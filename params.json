{
  "name": "A Cache Coherence Simulator with Transactional Memory",
  "tagline": "Using Contech",
  "body": "#Cache Coherence Simulator with Transactional Memory\r\n\r\n##Final Write Up\r\n\r\n###Summary\r\nThe Cache Coherence Simulator simulates a multiprocessor snooping-based system that uses the MESI cache coherence protocol with a split transaction bus. The simulator models a multiprocessor system, where each processor has a variable sized L1 4-way associative LRU cache. The simulator can also model transactional memory.\r\n\r\nUsing the simulation, we have compared the performance of several Contech traces across a range of different parameters, such as the maximum number of outstanding requests on the bus, and the number of cycles it takes to receive data from memory. Performance was measured using the total number of cache hits, misses, and evictions, as well as total clock cycle count, and bus contention.\r\n\r\n###Background\r\nThis project uses Contech memory traces, or taskgraphs, for each parallel program. Using these memory traces, we were able to simulate a program running on a multiprocessor machine, where each thread in the taskgraph is scheduled to a single core with an L1 cache.\r\n\r\nThe simulator keeps track of several statistics as it iterates through the parallel memory trace. These statistics include cache hits, misses, and evictions for each individual L1 cache, as well as the number of times each processor requested the bus, the number of times each processor won the bus, and the total number of clock cycles it takes for the program to complete.\r\n\r\nThese measurements were recorded as several parameters were adjusted, including the maximum number of outstanding requests on the bus, and the number of cycles it takes to receive data from memory.\r\n\r\nThe simulator is also able to model transactional memory. Using a transactional memory trace that we created, the simulator is able to emulate the behavior of a hardware transactional memory system with a MESI cache coherence protocol. The simulation results were then compared against results from the same program with locks instead of atomic blocks.\r\n\r\n###Approach\r\nThe simulator is constructed to reflect the hardware, so each major component of the hardware can be seen in the software, where the overall simulator contains the caches, the interconnect, and the transactional memory layer. The system input is a Contech taskgraph, and the outputs are the cache coherence statistics.\r\n\r\n####The Contech Taskgraph\r\nThe simulator, written in C++, uses the input taskgraph file to create a list of memory accesses from each core. Special cases are made during runtime to handle locks and barriers and thread synchronization, that included a map of locked elements.\r\n\r\n####The Cache\r\nWe started with a simple single core cache simulator, similar to what we created in the 15-213 cachelab assignment, that was provided in the contech github repo (Simple Cache) by Professor Railing.\r\nUsing the list of memory accesses from the taskgraph, the simulator sends each individual processor its memory requests, and must mediate between each processor requesting data on the bus. To do so, each memory request is initially separated into 8 byte requests of either reads or writes (a mem copy is considered to be both). The simulator then must find the cache line that corresponds to the given address, and check the state that the cache line is in. Depending on the state and type of operation, the processor sends a request to the split bus interconnect, according to the MESI protocol.\r\n\r\n####The Interconnect: A Split Transaction Bus\r\nThe bus takes the request, and saves it on the request table. If the request table is full then the bus will return with a NACK, and a retry will have to occur. Once the request has been held for a given time period (modeling how long loading data from memory takes), the bus notifies all of the other processors about the request and each processor updates its L1 cache accordingly. The bus then returns to the simulator letting the requesting cache know that it can change its own state accordingly as well.\r\n\r\n####Transactional Memory\r\nIn order to simulate lazy optimistic transactional memory, on top of the MESI split bus, we first had to build a simple memory trace that mimicked transactions being sent. Each transaction had a read and write, simulating depositing and withdrawing from a bank, as an example. Upon a commit, each memory instruction that was supposed to have occured gets sent to the split bus, if needed, according to MESI protocol. When it is time for the bus to broadcast the message, each processor checks if any of the values in their read/write set conflict with the committed data according to the lazy optimistic protocol. If so the given processor must abort and restart its transaction by clearing its read/write set and beginning the operations again.\r\n\r\n###Results\r\n![Number of Hits - Black Taskgraph](https://github.com/ryanovsky/contech/blob/master/backend/CacheCoherence/black_hits.png)\r\nGraphs will be up soon.  So far the data makes sense and is as expected.\r\nWe varied 2 parameters, the total time it takes to retrieve data from memory and the maximum number of outstanding requests, while running simulations on several benchmark program traces. We are also varying the size of the caches to see the effect of the entire data set fitting in cache. The results can be seen below.\r\n[Graphs of results]\r\n\r\n\r\n###References\r\nWe used Contech documentation, as well as Contech task graphs as traces for our simulation.\r\n\r\n###General Contech info\r\nContech is a compiler-based (specifically LLVM) instrumentation, designed to efficiently record the execution trace, memory accesses, and parallel interactions of a program. The instrumentation has been tested across programs written in C, C++, and Fortran, as well as those using pthreads, OpenMP, and MPI.\r\nContech is documented in the wiki.\r\nAuthors and Contributors @bprail is the software architect of this project. Contributions have also been made by @ehein6. Additional components have been provided by @caparrov.\r\nPublication Contech has appeared in the journal, ACM Transactions on Architecture and Code Optimization.\r\nContech appeared as a tutorial at IISWC 2015.\r\n\r\n###List of work by each Student\r\nEqual work was performed by both project members. We met up and each did all of the work together.\r\n\r\n##Project Checkpoint\r\n### Summary\r\nWe are going to implement a backend application for Contech that will simulate the MESI protocol on a split transaction bus. We will then use our simulation to measure bus traffic and contention.\r\n\r\n### Schedule\r\nApril 4-10: Contech Research and basic MSI for quad-core\r\nApril 11-17: Implement MESI\r\nApril 18-20: Change the ordering that memory goes to the bus\r\nApril 21-26: Split transaction\r\nApril 27 - May 2: Implement a ring interconnect \r\nMay 3- 9: Create a presentation, do analysis, compare the ring to the split transaction memory bus\r\n\r\n### Completed work so far\r\nWe have learned how to use Contech.  Initially, our simulation traverses a contech TaskGraph and orders the memory requests based on when they would be completed.  We then begin simulating the MESI protocol, by sending requests to the bus, which updates the state of all the caches.  Once the bus returns, then the given memory request can be put in the owners cache.  As of now, we arbitrarily chose how many clock cycles each event will take.  These events include a memory flush, memory load, and L1 cache hit.\r\n\r\nWe still have a lot of work that needs to be done.  First we have to reorder the way that memory is sent to the bus.  We have to implement a split transaction bus, and then look into creating a ring bus as well.\r\n\r\nWe do not expect to come across any unknown challenges, but we still have to look into a ring bus in more detail, we believe it is just a matter of coding.  After we finish implementing the split transaction bus, we may choose to not do the ring bus but instead do directory based cache coherence (we do not want to lock ourselves into the ring idea).\r\n\r\n### Results\r\nOur results will be a set of graphs and analysis, of hits and misses over time created from different Contech TaskGraphs. \r\n\r\n\r\n\r\n\r\n\r\n### General Contech info\r\nContech is a compiler-based (specifically [LLVM](http://llvm.org)) instrumentation, designed to efficiently record the execution trace, memory accesses, and parallel interactions of a program.  The instrumentation has been tested across programs written in C, C++, and Fortran, as well as those using pthreads, OpenMP, and MPI.\r\n\r\nContech is documented in the [wiki](https://github.com/bprail/contech/wiki/Contech).\r\n\r\nAuthors and Contributors\r\n@bprail is the software architect of this project.  Contributions have also been made by @ehein6.  Additional components have been provided by @caparrov.\r\n\r\nPublication\r\nContech has appeared in the journal, [ACM Transactions on Architecture and Code Optimization](http://dx.doi.org/10.1145/2776893).\r\n\r\nContech appeared as a tutorial at [IISWC 2015](http://www.iiswc.org/iiswc2015/index.html).\r\n",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}